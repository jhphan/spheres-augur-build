#####################################################################################
#### NOTE: head over to `builds.yaml` to define what builds you'd like to run. ####
#### (i.e., datasets and subsampling schemas)  ####
#####################################################################################

configfile:
  - spheres_profile/builds.yaml

# Always print the commands that will be run to the screen for debugging.
printshellcmds: True

# Explain why Snakemake is running each rule.
reason: True

# Track how long each step of builds takes to rum.
stats: stats.json

# Use conda environments for augur and related binaries. This is important in a
# cluster environment where Docker is not available and Singularity may be
# prohibitively complicated to setup.
use-conda: True

#
# OPTIONAL: Setup config for running builds on a SLURM cluster.
#

# Run no more than this many jobs at once on the cluster.
cores: 100

# On failure of one or more jobs, try to finish running all other jobs until the
# workflow has to be restarted.
keep-going: True

# Cluster-specific settings for resources required by any rule. This file
# provides default resources for all rules and allows users to specify resources
# per rule by name. An important resource for the Hutch cluster is the requested
# "partition". Jobs submitted to the "restart" partition will start running
# almost immediately, but they may also be killed at any moment when someone
# else needs those resources. This is analogous to the spot resources on AWS.
cluster-config: spheres_profile/cluster.json

# Submit jobs to the cluster with SLURM's sbatch command. The string associated
# with this key tells SLURM how to map cluster resources with those defined in
# the cluster config above.
cluster: "sbatch {cluster.partition} --nodes=1 --ntasks=1 --mem={cluster.memory} --cpus-per-task={cluster.cores} --tmp={cluster.disk} --time={cluster.time}"

# Use a custom script to evaluate the status of jobs on the cluster. This
# prevents jobs from dying silently and not being caught by Snakemake.
cluster-status: "slurm-status.py"

# Wait a fixed number of seconds for missing files since the cluster file system
# can be quite slow and the workflow can fail unnecessarily due to this latency.
latency-wait: 60

# Restart failed jobs multiple times since the cluster may kill our jobs
# whenever another job with higher priority comes along.
restart-times: 3

# Limit job submission and status checks
max-jobs-per-second: 1
max-status-checks-per-second: 1

# Limit cores used on the head node where Snakemake is running.
local-cores: 1

# Set the name for the job as display in the cluster queue.
jobname: "{rulename}.{jobid}.sh"

# Set the number of threads (cores, actually) that the tree rule or other rules
# should use on the cluster. These settings override the hardcoded values in the
# Snakemake rules.
set-threads: tree=8
